{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\emreq\\Desktop\\Genel\\.venv\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSearch:\n",
    "    def __init__(self, documents):\n",
    "        self.model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "        self.documents = documents\n",
    "        self.document_embeddings = self.model.encode(documents)\n",
    "        \n",
    "    def retriver(self,query,topk = 5):\n",
    "        query_embedding = self.model.encode(query)\n",
    "        scores = np.dot(self.document_embeddings, query_embedding.T)\n",
    "        top_indices = np.argsort(scores)[::-1][:topk]\n",
    "        top_documents = [self.documents[i] for i in top_indices]\n",
    "        return top_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Retrieval Results: ['Semantic retrieval uses deep learning models.', 'BM25 is a ranking function used in information retrieval.', 'Both methods have their own advantages and disadvantages.']\n",
      "BM25 Retrieval Results: ['BM25 is a ranking function used in information retrieval.', 'Both methods have their own advantages and disadvantages.', 'Semantic retrieval uses deep learning models.']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "class SemanticRetriever:\n",
    "    def __init__(self, documents):\n",
    "        self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        # Store embeddings and keep them on CPU\n",
    "        self.document_embeddings = self.model.encode(documents, convert_to_tensor=True)\n",
    "        if torch.is_tensor(self.document_embeddings):\n",
    "            self.document_embeddings = self.document_embeddings.cpu()\n",
    "\n",
    "    def retrieve(self, query, top_k=5):\n",
    "        query_embedding = self.model.encode(query, convert_to_tensor=True)\n",
    "        if torch.is_tensor(query_embedding):\n",
    "            query_embedding = query_embedding.cpu()\n",
    "            \n",
    "        # Now we can safely perform numpy operations\n",
    "        scores = np.dot(self.document_embeddings.numpy(), query_embedding.numpy().T)\n",
    "        top_indices = np.argsort(scores, axis=0)[-top_k:][::-1]\n",
    "        return top_indices.flatten()  # Flatten to handle the case when it's a 2D array\n",
    "\n",
    "class BM25Retriever:\n",
    "    def __init__(self, documents):\n",
    "        tokenized_documents = [doc.split(\" \") for doc in documents]\n",
    "        self.bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "    def retrieve(self, query, top_k=5):\n",
    "        tokenized_query = query.split(\" \")\n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "        return top_indices\n",
    "\n",
    "class SearchEngine:\n",
    "    def __init__(self, documents):\n",
    "        self.semantic_retriever = SemanticRetriever(documents)\n",
    "        self.bm25_retriever = BM25Retriever(documents)\n",
    "        self.documents = documents\n",
    "\n",
    "    def search(self, query, retriever_type='semantic', top_k=5):\n",
    "        if retriever_type == 'semantic':\n",
    "            top_indices = self.semantic_retriever.retrieve(query, top_k)\n",
    "        elif retriever_type == 'bm25':\n",
    "            top_indices = self.bm25_retriever.retrieve(query, top_k)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid retriever type. Choose 'semantic' or 'bm25'.\")\n",
    "\n",
    "        return [self.documents[i] for i in top_indices]\n",
    "\n",
    "# Example usage\n",
    "documents = [\n",
    "    \"Semantic retrieval uses deep learning models.\",\n",
    "    \"BM25 is a ranking function used in information retrieval.\",\n",
    "    \"Both methods have their own advantages and disadvantages.\"\n",
    "]\n",
    "\n",
    "search_engine = SearchEngine(documents)\n",
    "results = search_engine.search(\"deep learning\", retriever_type='semantic')\n",
    "print(\"Semantic Retrieval Results:\", results)\n",
    "\n",
    "results = search_engine.search(\"ranking function\", retriever_type='bm25')\n",
    "print(\"BM25 Retrieval Results:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
